# -*- coding: utf-8 -*-
"""Untitled6.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1W19xDpvr0R_WUgG6zfwTmnWPlOY1hG34
"""

import os
import json
import csv
import pandas as pd

def process_data(input_csv, json_directory, output_csv):
    json_files = {}

    for root, _, files in os.walk(json_directory):
        for _file in files:
            if _file.endswith(".json"):
                _file_name = os.path.splitext(_file)[0]
                json_files[_file_name] = os.path.join(root, _file)

    with open(input_csv) as f_in, open(output_csv, 'w') as f_out:
        reader = csv.reader(f_in)
        writer = csv.writer(f_out)
        next(reader)

        # Add labels to the header
        labels = ['pair_id', 'text1', 'text2', 'Geography', 'Entities', 'Time', 'Narrative', 'Overall', 'Style', 'Tone']
        writer.writerow(labels)

        for row in reader:
            id1, id2 = row[2].split("_")
            text_1 = text_2 = None

            if id1 in json_files:
                with open(json_files[id1]) as f1:
                    data1 = json.load(f1)
                    text_1 = [data1['title'] + '  [SEP]  ' + data1['text']]

            if id2 in json_files:
                with open(json_files[id2]) as f2:
                    data2 = json.load(f2)
                    text_2 = [data2['title'] + '  [SEP]  ' + data2['text']]

            if text_1 and text_2:
                writer.writerow(row[:3] + text_1 + text_2 + row[7:])


process_data('/content/final_evaluation_data.csv', '/content/output_dir_test', 'test.csv')

test_data = pd.read_csv('/content/test.csv')
test_data = test_data.dropna(subset=['text1', 'text2']).astype({'text1': 'str', 'text2': 'str'})

import re


class Preprocessor:
    def __init__(self, punctuation=True, url=True, number=True):
        self.punctuation = punctuation
        self.url = url
        self.number = number

    def apply(self, sentence: str) -> str:
        sentence = sentence.lower()
        sentence = sentence.replace('<unk>', '')
        if self.url:
            sentence = Preprocessor.remove_url(sentence)
        if self.punctuation:
            sentence = Preprocessor.remove_punctuation(sentence)
        if self.number:
            sentence = Preprocessor.remove_number(sentence)
        sentence = re.sub(r'\s+', ' ', sentence)
        return sentence

    @staticmethod
    def remove_punctuation(sentence: str) -> str:
        sentence = re.sub(r'[^\w\s]', ' ', sentence)
        return sentence

    @staticmethod
    def remove_url(sentence: str) -> str:
        sentence = re.sub(r'(https|http)?://(\w|\.|/|\?|=|&|%)*\b', ' ', sentence)
        return sentence

    @staticmethod
    def remove_number(sentence: str) -> str:
        sentence = re.sub(r'\d+', ' ', sentence)
        return sentence

# Clean the text data
preprocessor = Preprocessor()
test_data['text1'] = test_data['text1'].apply(preprocessor.apply)
test_data['text2'] = test_data['text2'].apply(preprocessor.apply)

from sentence_transformers import SentenceTransformer
import numpy as np

# Load the SentenceTransformer model
encodding_model = SentenceTransformer('paraphrase-multilingual-mpnet-base-v2')

print("model loded")

# Tokenize and encode the test set using the SentenceTransformer model
encoded_articles1_test = np.array(encodding_model.encode(test_data['text1'].tolist()))
encoded_articles2_test = np.array(encodding_model.encode(test_data['text2'].tolist()))

from tensorflow.keras.models import load_model
from sklearn.metrics import mean_absolute_error

# Load saved model
model = load_model('/content/saved_model.h5')

similarity_scores_test = model.predict([encoded_articles1_test, encoded_articles2_test])
similarity_scores_test = np.round(similarity_scores_test).clip(1, 4)
mae_test = mean_absolute_error(test_data['Overall'], similarity_scores_test)

print("Test MAE", mae_test)